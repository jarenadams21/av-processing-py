# Purpose
This repository explores audio and image processing, wave concepts like signals & pulses, and use cases in the context of python.

# Setup (can be abstracted)

1. Create a virtual python environment
- python -m venv tutorial-env
- source tutorial-env/bin/activate

2. Use pip to manage packages (here i am installing Gradio)
- pip install gradio

3. The demo below will appear automatically within the Jupyter Notebook, or pop in a browser on http://localhost:7860 if running from a script

* Target file : signal.py
- using 'gradio signal.py' will run the file with automatic refresh

> Make sure new files are correctly placed in environment directory

# audio-samples.py
## Function: mel_spectrogram
This function converts an audio signal into a mel spectrogram that better reflects how a human would perceive audio. It uses a logarithmic decibel-based analysis which emphasizes that humans are more sensitive to changes in lower frequency sounds than higher (think about percentages of 100hz and 200hz as opposed to 1000hz and 1010hz)
```
def mel_spectrogram(audio):
    print(audio)

    # Process audio input from user
    audio_file = open(audio, "rb")

    # Gather all samples and sample rate to be used in Spectrogram
    samples, sample_rate = librosa.load(audio_file, sr=None)

    # Create a plot
    ## Calculate time values in seconds
    start_sample = 0  # Start at the beginning
    end_sample = int(30 * sample_rate)  # End at 30 seconds
    segment_samples = samples[start_sample:end_sample]

    # Create a plot
    # Calculate time values in seconds for the segment
    time = np.linspace(0, len(segment_samples) / sample_rate, num=len(segment_samples))

    # Create a Mel scale spectrogram for the segment
    sgram = librosa.stft(segment_samples)
    sgram_mag, _ = librosa.magphase(sgram)
    mel_scale_sgram = librosa.feature.melspectrogram(S=sgram_mag, sr=sample_rate)
    mel_sgram = librosa.amplitude_to_db(mel_scale_sgram, ref=np.min)

    # Display the Mel spectrogram
    librosa.display.specshow(mel_sgram, sr=sample_rate, x_axis='time', y_axis='mel')
    plt.colorbar(format='%+2.0f dB')
    plt.show()


    # Save the plot to a buffer
    buf = BytesIO()
    plt.savefig(buf, format='png')
    buf.seek(0)

    # Convert buffer to PIL image
    image = Image.open(buf)

    # Close the figure
    plt.close()

    return image
```

## Function: time_domain
This function utilizes Gradio to capture audio input and plots its time-domain visualization. In the time domain, a sound wave is represented in terms of its amplitude variations over time. The plot generated by this function displays these amplitude fluctuations, providing a visual representation of the audio signal's loudness and silence at different moments.
```
# Signalling function to process audio from input
## Plots Amplitude against Time (Time Domain)
def time_domain(audio):
    print(audio)

    # Process audio input from user
    audio_file = open(audio, "rb")

    # Gather all samples and sample rate to be used in Spectrogram
    samples, sample_rate = librosa.load(audio_file, sr=None)

    # Create a plot
    ## Calculate time values in seconds
    time = np.linspace(0, len(samples) / sample_rate, num=len(samples))

    # Create a plot
    plt.figure(figsize=(14, 5))
    plt.plot(time, samples)
    plt.xlabel('Time (s)')
    plt.ylabel('Amplitude')


    # Save the plot to a buffer
    buf = BytesIO()
    plt.savefig(buf, format='png')
    buf.seek(0)

    # Convert buffer to PIL image
    image = Image.open(buf)

    # Close the figure
    plt.close()

    return image
```


# Helpful Recalls
## Signals
In the broadest sense, a signal is any quantity that varies over time, space, or any other variable. In the context of audio and electronics, a signal often refers to a varying voltage or current that represents information. For audio, this signal is typically a representation of sound pressure variations converted into an electrical form.

## Baselines
Generally refers to a reference or starting level from which other measurements or values are compared. In signal processing, the baseline could be considered the "zero level" or a resting state of the signal. For a sound wave, this might be the level of no sound or ambient sound.

## Waves (audio)
A wave or waveform is a graphical representation of the sound signal. It shows how the sound pressure (amplitude) varies over time. A single frequency sound wave would appear as a regular and repeating pattern (like a sine wave), while real-world audio signals are usually much more complex.

## Pulses
Refer to short bursts or transients in a signal. They are typically characterized by a sudden change in the signal's amplitude, followed by a return to the baseline or zero level. In digital electronics, pulses are used to convey information (like in digital clocks), while in audio, a pulse might be a short, sharp sound like a drum beat or a clap.
### More on pulses in the context of digital clocks
The regularity of these pulses is crucial. In a digital clock, these pulses are used to measure time. By counting a fixed number of pulses, the clock can measure seconds, minutes, and hours. For example, if the crystal oscillator generates a frequency of 1 Hz, it produces one pulse per second. The clock circuitry counts these pulses to keep track of time.
# Random Programming Notes

* The difference between gr.Audio(source='microphone') and gr.Audio(source='microphone', streaming=True), when both are used in gr.Interface(live=True), is that the first Component will automatically submit data and run the Interface function when the user stops recording, whereas the second Component will continuously send data and run the Interface function during recording.


* Example code of streaming images from webcam
```
import gradio as gr
import numpy as np

def flip(im):
    return np.flipud(im)

demo = gr.Interface(
    flip, 
    gr.Image(sources=["webcam"], streaming=True), 
    "image",
    live=True
)
demo.launch()
```